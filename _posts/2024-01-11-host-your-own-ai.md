---
title: Host your own AI
author: cr
date: 2024-01-11 18:00:00 +0800
categories: [Tutorial, AI]
tags: [ai, self-hosted]
published: true
---

## Einleitung
In diesem Blogpost m√∂chte ich Ihnen zeigen, wie Sie eine KI in Ihrer <b>Firma</b> oder <b>privat</b> nutzen k√∂nnnen, ohne auf Services Dritter zur√ºckgreifen zu m√ºssen. Dazu werde ich Ihnen anhand eines Beispiel-Projektes zeigen, wie ein Einsatz aussehen k√∂nnte. Das Tool, das wir hierzu verwenden hei√üt [Ollama]("https://ollama.ai/").

Zu Beginn sollten wir jedoch erst einmal kl√§ren, aus was eine KI eigentlich besteht. 
Eine KI besteht aus zwei Teilen: dem Modell und den Daten. Das Modell (auch bekannt als LLM) ist eine mathematische Funktion, die aus den Daten gelernt hat. Das Modell kann dann auf neue Daten angewendet werden.

## Ollama - Was ist das?
Wir benutzen das OpenSource Tool [Ollama]("https://ollama.ai/") um unsere KI zu hosten. Ollama ist ein Tool, das es uns erm√∂glicht, unsere KI auf einem eigenen Server, aber auch lokal am eigenen PC zu hosten. Dies inkludiert, dass keine Daten an Dritte weitergegeben werden. Das Tool funktioniert derzeit nur unter Linux und MacOS. Eine Windows Version ist jedoch in finaler Arbeit und wird demn√§chst noch kommen.

## Ollama - Installation
Das Tool zu installieren ist sehr einfach.
F√ºr MacOS:
-> Einfach die .zip Datei herunterladen und die darin enthaltene Datei installieren.

F√ºr Linux:
-> Folgenden Befehl ausf√ºhren
```
curl https://ollama.ai/install.sh | sh
```


## Ollama - Erste Schritte
Nachdem wir das Tool installiert haben, k√∂nnen wir es auch schon starten. Dazu m√ºssen wir einfach nur den Befehl "ollama run [modelname]" in der Konsole ausf√ºhren. 
Eine Liste aller verf√ºgbaren Modelle finden Sie [hier]("https://ollama.ai/library").

In unserem Beispiel nehmen wir das von Meta (ehemals Facebook) entwickelte Modell "llama2".
>ACHTUNG: Das Modell hat keine Apache 2.0 Lizenz und darf daher nicht kommerziell genutzt werden. Daher grundlegend immer die Lizenz des Modells pr√ºfen.
{: .prompt-tip }
```
ollama run llama2
```


## KI erfolgreich nutzen
Nachdem wir das Modell gestartet haben, k√∂nnen wir es auch schon nutzen. Dazu m√ºssen wir nur noch die IP-Adresse des Servers herausfinden.

Hier ein Beispiel, wie Sie ihre KI nutzen k√∂nnen
```
curl http://localhost:11434/api/generate -d '{
  "model": "llama2",
  "prompt":"Was ist eine Erdbeere?"
}'
```
<br>
<br>
<br>

# Und das wars auch schon! üöÄ
Sie k√∂nnen nun Ihre KI nutzen. Viel Spa√ü damit!
Wenn Sie Fragen haben, k√∂nnen Sie mich gerne kontaktieren. Ich werde in naher Zukunft noch ein Tutorial ver√∂ffentlichen, indem es darum geht, wie Sie Ihre eigene KI in Kombination mit ihren Gesch√§ftsdaten nutzen k√∂nnen.